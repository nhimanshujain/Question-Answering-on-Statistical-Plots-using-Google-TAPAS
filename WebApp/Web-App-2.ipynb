{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":49643,"status":"ok","timestamp":1635159998953,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"8n1SB5X1t9Mb","outputId":"06c9f363-3e87-4b18-cc5f-49ebc8ab19ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tapas-table-parsing in /usr/local/lib/python3.7/dist-packages (0.0.1.dev0)\n","Requirement already satisfied: scikit-learn~=0.22.1 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (0.22.2.post1)\n","Requirement already satisfied: pandas~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (1.0.5)\n","Requirement already satisfied: tf-models-official~=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (2.2.2)\n","Requirement already satisfied: tf-slim~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (1.1.0)\n","Requirement already satisfied: apache-beam[gcp]==2.20.0 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (2.20.0)\n","Requirement already satisfied: kaggle\u003c1.5.8 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (1.5.6)\n","Requirement already satisfied: nltk~=3.5 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (3.6.5)\n","Requirement already satisfied: tensorflow-probability==0.10.1 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (0.10.1)\n","Requirement already satisfied: frozendict==1.2 in /usr/local/lib/python3.7/dist-packages (from tapas-table-parsing) (1.2)\n","Collecting tensorflow~=2.2.0\n","  Using cached tensorflow-2.2.3-cp37-cp37m-manylinux2010_x86_64.whl (516.4 MB)\n","Requirement already satisfied: protobuf\u003c4,\u003e=3.5.0.post1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.17.3)\n","Requirement already satisfied: pydot\u003c2,\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.3.0)\n","Requirement already satisfied: mock\u003c3.0.0,\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.0.0)\n","Requirement already satisfied: oauth2client\u003c4,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.0.0)\n","Requirement already satisfied: fastavro\u003c0.22,\u003e=0.21.4 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.21.24)\n","Requirement already satisfied: grpcio\u003c2,\u003e=1.12.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.41.0)\n","Requirement already satisfied: python-dateutil\u003c3,\u003e=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2018.9)\n","Requirement already satisfied: typing-extensions\u003c3.8.0,\u003e=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.7.4.3)\n","Requirement already satisfied: pyarrow\u003c0.17.0,\u003e=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.16.0)\n","Requirement already satisfied: hdfs\u003c3.0.0,\u003e=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.6.0)\n","Requirement already satisfied: httplib2\u003c=0.12.0,\u003e=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.12.0)\n","Requirement already satisfied: future\u003c1.0.0,\u003e=0.16.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.16.0)\n","Requirement already satisfied: dill\u003c0.3.2,\u003e=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.3.1.1)\n","Requirement already satisfied: avro-python3!=1.9.2,\u003c1.10.0,\u003e=1.8.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.9.2.1)\n","Requirement already satisfied: crcmod\u003c2.0,\u003e=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.7)\n","Requirement already satisfied: pymongo\u003c4.0.0,\u003e=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.12.0)\n","Requirement already satisfied: numpy\u003c2,\u003e=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.19.5)\n","Requirement already satisfied: google-cloud-dlp\u003c=0.13.0,\u003e=0.12.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.13.0)\n","Requirement already satisfied: cachetools\u003c4,\u003e=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.1.1)\n","Requirement already satisfied: google-cloud-core\u003c2,\u003e=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.0.3)\n","Requirement already satisfied: google-cloud-spanner\u003c1.14.0,\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.13.0)\n","Requirement already satisfied: google-apitools\u003c0.5.29,\u003e=0.5.28 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.5.28)\n","Requirement already satisfied: google-cloud-language\u003c2,\u003e=1.3.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.3.0)\n","Requirement already satisfied: google-cloud-datastore\u003c1.8.0,\u003e=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.7.4)\n","Requirement already satisfied: google-cloud-bigtable\u003c1.1.0,\u003e=0.31.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.0.0)\n","Requirement already satisfied: google-cloud-pubsub\u003c1.1.0,\u003e=0.39.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.0.2)\n","Requirement already satisfied: grpcio-gcp\u003c1,\u003e=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.2.2)\n","Requirement already satisfied: google-cloud-bigquery\u003c=1.24.0,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.21.0)\n","Requirement already satisfied: google-cloud-vision\u003c0.43.0,\u003e=0.38.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.42.0)\n","Requirement already satisfied: google-cloud-videointelligence\u003c1.14.0,\u003e=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.13.0)\n","Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.10.1-\u003etapas-table-parsing) (1.3.0)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.10.1-\u003etapas-table-parsing) (1.15.0)\n","Requirement already satisfied: gast\u003e=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.10.1-\u003etapas-table-parsing) (0.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.10.1-\u003etapas-table-parsing) (4.4.2)\n","Requirement already satisfied: fasteners\u003e=0.14 in /usr/local/lib/python3.7/dist-packages (from google-apitools\u003c0.5.29,\u003e=0.5.28-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.16.3)\n","Requirement already satisfied: google-resumable-media!=0.4.0,\u003c0.5.0dev,\u003e=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery\u003c=1.24.0,\u003e=1.6.0-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.4.1)\n","Requirement already satisfied: grpc-google-iam-v1\u003c0.13dev,\u003e=0.12.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.12.3)\n","Requirement already satisfied: google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.26.3)\n","Requirement already satisfied: requests\u003c3.0.0dev,\u003e=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.23.0)\n","Requirement already satisfied: setuptools\u003e=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (57.4.0)\n","Requirement already satisfied: packaging\u003e=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (21.0)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0dev,\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.53.0)\n","Requirement already satisfied: google-auth\u003c2.0dev,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (1.35.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.2.8)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2.0dev,\u003e=1.21.1-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (4.7.2)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs\u003c3.0.0,\u003e=2.1.0-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.6.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle\u003c1.5.8-\u003etapas-table-parsing) (2021.5.30)\n","Requirement already satisfied: urllib3\u003c1.25,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from kaggle\u003c1.5.8-\u003etapas-table-parsing) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle\u003c1.5.8-\u003etapas-table-parsing) (5.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle\u003c1.5.8-\u003etapas-table-parsing) (4.62.3)\n","Requirement already satisfied: pbr\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from mock\u003c3.0.0,\u003e=1.0.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (5.6.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk~=3.5-\u003etapas-table-parsing) (7.1.2)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk~=3.5-\u003etapas-table-parsing) (2021.10.23)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk~=3.5-\u003etapas-table-parsing) (1.0.1)\n","Requirement already satisfied: pyasn1\u003e=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client\u003c4,\u003e=2.0.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (0.4.8)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=14.3-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.4.7)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3.0.0dev,\u003e=2.18.0-\u003egoogle-api-core[grpc]\u003c2.0.0dev,\u003e=1.14.0-\u003egoogle-cloud-bigtable\u003c1.1.0,\u003e=0.31.1-\u003eapache-beam[gcp]==2.20.0-\u003etapas-table-parsing) (2.10)\n","Requirement already satisfied: scipy\u003e=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=0.22.1-\u003etapas-table-parsing) (1.4.1)\n","Collecting h5py\u003c2.11.0,\u003e=2.10.0\n","  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","Collecting numpy\u003c2,\u003e=1.14.3\n","  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (3.3.0)\n","Requirement already satisfied: keras-preprocessing\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (1.1.2)\n","Collecting gast\u003e=0.3.2\n","  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Collecting tensorflow-estimator\u003c2.3.0,\u003e=2.2.0\n","  Using cached tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (0.37.0)\n","Collecting tensorboard\u003c2.3.0,\u003e=2.2.0\n","  Using cached tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n","Requirement already satisfied: wrapt\u003e=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (1.12.1)\n","Requirement already satisfied: google-pasta\u003e=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (0.2.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (1.1.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (1.6.3)\n","Requirement already satisfied: absl-py\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.2.0-\u003etapas-table-parsing) (0.12.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (1.8.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (0.4.6)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (4.8.1)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (3.1.1)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.14.0)\n","Requirement already satisfied: py-cpuinfo\u003e=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (8.0.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (7.1.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.29.24)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (3.2.2)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.4.0)\n","Requirement already satisfied: typing==3.7.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (3.7.4.1)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (4.0.1)\n","Requirement already satisfied: tensorflow-model-optimization\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.7.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.6)\n","Requirement already satisfied: psutil\u003e=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (5.4.8)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.1.96)\n","Requirement already satisfied: mlperf-compliance==0.0.10 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.0.10)\n","Requirement already satisfied: tensorflow-hub\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (0.12.0)\n","Requirement already satisfied: google-api-python-client\u003e=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (1.12.2)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (4.5.4.58)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.2.0-\u003etapas-table-parsing) (3.13)\n","Requirement already satisfied: google-auth-httplib2\u003e=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (0.0.4)\n","Requirement already satisfied: uritemplate\u003c4dev,\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (3.0.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization\u003e=0.2.1-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (0.1.6)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c2.3.0,\u003e=2.2.0-\u003etensorflow~=2.2.0-\u003etapas-table-parsing) (3.6.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (0.10.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (1.3.2)\n","Requirement already satisfied: text-unidecode\u003e=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-\u003ekaggle\u003c1.5.8-\u003etapas-table-parsing) (1.3)\n","Requirement already satisfied: typeguard\u003e=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (2.7.1)\n","Requirement already satisfied: attrs\u003e=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (21.2.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (1.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (5.2.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets-\u003etf-models-official~=2.2.0-\u003etapas-table-parsing) (2.3)\n","Installing collected packages: numpy, tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.7.0\n","    Uninstalling tensorboard-2.7.0:\n","      Successfully uninstalled tensorboard-2.7.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.6.0\n","    Uninstalling tensorflow-2.6.0:\n","      Successfully uninstalled tensorflow-2.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pymc3 3.11.4 requires cachetools\u003e=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version \u003e= \"3.0\", but you have pandas 1.0.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug\u003c0.2.7,\u003e=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed gast-0.3.3 h5py-2.10.0 numpy-1.18.5 tensorboard-2.2.2 tensorflow-2.2.3 tensorflow-estimator-2.2.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","h5py","numpy","tensorboard","tensorflow"]}}},"metadata":{},"output_type":"display_data"}],"source":["! pip install tapas-table-parsing"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151654,"status":"ok","timestamp":1635159622371,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"06fK_goyuKpC","outputId":"40714ced-42f1-4e87-f19f-472fa5f019fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying gs://tapas_models/2020_10_07/tapas_wtq_wikisql_sqa_inter_masklm_large_reset.zip...\n","| [1 files][  3.4 GiB/  3.4 GiB]   56.2 MiB/s                                   \n","Operation completed over 1 objects/3.4 GiB.                                      \n","Archive:  tapas_model.zip\n","   creating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/\n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/bert_config.json  \n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/README.txt  \n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/model.ckpt.index  \n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/model.ckpt.data-00000-of-00001  \n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/vocab.txt  \n","  inflating: tapas_wtq_wikisql_sqa_inter_masklm_large_reset/model.ckpt.meta  \n"]}],"source":["! gsutil cp \"gs://tapas_models/2020_10_07/tapas_wtq_wikisql_sqa_inter_masklm_large_reset.zip\" \"tapas_model.zip\" \u0026\u0026 unzip tapas_model.zip\n","! mv tapas_wtq_wikisql_sqa_inter_masklm_large_reset tapas_model"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132752,"status":"ok","timestamp":1635159755070,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"Cvo5rej5uLei","outputId":"f28541c3-3b45-4c34-9b1b-69583dc8efad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying gs://tapas_models/2020_10_07/tapas_tabfact_inter_masklm_large_reset.zip...\n","\\ [1 files][  3.4 GiB/  3.4 GiB]   55.2 MiB/s                                   \n","Operation completed over 1 objects/3.4 GiB.                                      \n","Archive:  tabfact_model.zip\n","   creating: tapas_tabfact_inter_masklm_large_reset/\n","  inflating: tapas_tabfact_inter_masklm_large_reset/bert_config.json  \n","  inflating: tapas_tabfact_inter_masklm_large_reset/README.txt  \n","  inflating: tapas_tabfact_inter_masklm_large_reset/model.ckpt.index  \n","  inflating: tapas_tabfact_inter_masklm_large_reset/model.ckpt.data-00000-of-00001  \n","  inflating: tapas_tabfact_inter_masklm_large_reset/vocab.txt  \n","  inflating: tapas_tabfact_inter_masklm_large_reset/model.ckpt.meta  \n"]}],"source":["! gsutil cp \"gs://tapas_models/2020_10_07/tapas_tabfact_inter_masklm_large_reset.zip\" \"tabfact_model.zip\" \u0026\u0026 unzip tabfact_model.zip\n","! mv tapas_tabfact_inter_masklm_large_reset tabfact_model"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":640,"status":"ok","timestamp":1635159755659,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"D-kxKVphuNzm"},"outputs":[],"source":["!rm /content/tabfact_model.zip /content/tapas_model.zip"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1635160008985,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"AYZ_qsVZuQ1H","outputId":"04f2db66-2d5b-48a4-95e2-c65831c0d9ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.6.0\n"]}],"source":["\n","from google.colab import files\n","import os\n","import glob\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import re\n","import json\n","from natsort import natsorted \n","import shutil\n","import pandas as pd\n","from statistics import median\n","from math import floor\n","from math import ceil\n","\n","import numpy as np\n","import pickle\n","%matplotlib inline\n","\n","import tensorflow.compat.v1 as tf\n","import os \n","import shutil\n","import csv\n","import pandas as pd\n","import numpy as np\n","import IPython\n","print(tf.__version__)\n","tf.get_logger().setLevel('ERROR')\n","\n","\n","\n","from tapas.utils import tf_example_utils\n","from tapas.protos import interaction_pb2\n","from tapas.utils import number_annotation_utils\n","import math\n","\n","\n","\n","\n","from tapas.utils import tf_example_utils\n","from tapas.protos import interaction_pb2\n","from tapas.utils import number_annotation_utils\n","from tapas.scripts import prediction_utils"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":69142,"status":"ok","timestamp":1635159920835,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"_QnZHBLluTeM","outputId":"a42c2044-0da5-4fca-9910-8b1f0ce4bb47"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.6\n","  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n","\u001b[K     |████████████████████████████████| 458.3 MB 5.8 kB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.12)\n","Collecting gast==0.4.0\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: protobuf\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.17.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (0.37.0)\n","Collecting tensorflow-estimator~=2.6\n","  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 52.3 MB/s \n","\u001b[?25hCollecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 248 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.7.4.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.12.1)\n","Collecting tensorboard~=2.6\n","  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 37.9 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio\u003c2.0,\u003e=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.41.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (3.3.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.15.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.6.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (0.2.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (0.12.0)\n","Collecting h5py~=3.1.0\n","  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 37.1 MB/s \n","\u001b[?25hRequirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (2.6.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (1.1.2)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6) (5.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0-\u003etensorflow==2.6) (1.5.2)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (0.4.6)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (1.0.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (3.3.4)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (0.6.1)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-\u003etensorflow==2.6) (2.23.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow==2.6) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow==2.6) (3.1.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow==2.6) (4.7.2)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow==2.6) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow==2.6) (4.8.1)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard~=2.6-\u003etensorflow==2.6) (0.4.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow==2.6) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow==2.6) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow==2.6) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard~=2.6-\u003etensorflow==2.6) (2021.5.30)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard~=2.6-\u003etensorflow==2.6) (3.1.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard~=2.6-\u003etensorflow==2.6) (3.6.0)\n","Installing collected packages: numpy, tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 2.10.0\n","    Uninstalling h5py-2.10.0:\n","      Successfully uninstalled h5py-2.10.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.2.3\n","    Uninstalling tensorflow-2.2.3:\n","      Successfully uninstalled tensorflow-2.2.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tapas-table-parsing 0.0.1.dev0 requires tensorflow~=2.2.0, but you have tensorflow 2.6.0 which is incompatible.\n","pymc3 3.11.4 requires cachetools\u003e=4.2.1, but you have cachetools 3.1.1 which is incompatible.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version \u003e= \"3.0\", but you have pandas 1.0.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug\u003c0.2.7,\u003e=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed gast-0.4.0 h5py-3.1.0 numpy-1.19.5 tensorboard-2.7.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","h5py","numpy","tensorboard","tensorflow"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install tensorflow==2.6"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4984,"status":"ok","timestamp":1635159942137,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"Y8O2SiSeuVpo","outputId":"5a19b591-4693-4af5-87d4-be99bc5cef23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1oZ3GAXeLAGBrwzMKPTO2J4tKwbC1Pjj9\n","To: /content/binary_classifier.h5\n","100% 800k/800k [00:00\u003c00:00, 52.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Rzqdy1ColCSEeAepu6QqZ3CSKS13Ahp4\n","To: /content/tokenizer.pickle\n","100% 48.6k/48.6k [00:00\u003c00:00, 28.3MB/s]\n"]}],"source":["#https://drive.google.com/file/d/1oZ3GAXeLAGBrwzMKPTO2J4tKwbC1Pjj9/view?usp=sharing -- binary_classifier.h5\n","#https://drive.google.com/file/d/1Rzqdy1ColCSEeAepu6QqZ3CSKS13Ahp4/view?usp=sharing --pickle\n","\n","!gdown -O \"binary_classifier.h5\" --id 1oZ3GAXeLAGBrwzMKPTO2J4tKwbC1Pjj9\n","!gdown -O \"tokenizer.pickle\" --id 1Rzqdy1ColCSEeAepu6QqZ3CSKS13Ahp4"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2861,"status":"ok","timestamp":1635159944987,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"KDFuToH7uYGe"},"outputs":[],"source":["import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pickle\n","\n","model = tensorflow.keras.models.load_model('/content/binary_classifier.h5')\n","\n","with open('/content/tokenizer.pickle', 'rb') as handle:\n","    loaded_tokenizer = pickle.load(handle)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1635159944988,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"3ZDqFvTAuaJJ"},"outputs":[],"source":["def binary_classifier_predict(questions):\n","  maxlen = 100\n","  seq= loaded_tokenizer.texts_to_sequences(questions)\n","  padded = pad_sequences(seq, maxlen=maxlen)\n","  predictions = model.predict(padded)\n","\n","  result = []\n","  for e in predictions:\n","    result.append(e[0])\n","\n","  THRESHOLD = 0.5\n","  tapas_questions = []\n","  tabfact_questions = []\n","  for i in range(len(result)):\n","      # print(\"Question = \", questions[i])\n","\n","      # Class 0\n","      if result[i] \u003c THRESHOLD:\n","          # print(\"Class 0: Tabfact\")\n","          tabfact_questions.append(questions[i])\n","\n","      else:\n","          # print(\"Class 1: Tapas\")\n","          tapas_questions.append(questions[i])\n","\n","  return tapas_questions, tabfact_questions"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":79015,"status":"ok","timestamp":1635160100365,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"rJ46rW_mucqe"},"outputs":[],"source":["os.makedirs('results/tabfact/tf_examples', exist_ok=True)\n","os.makedirs('results/tabfact/model', exist_ok=True)\n","with open('results/tabfact/model/checkpoint', 'w') as f:\n","  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n","for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n","  shutil.copyfile(f'tabfact_model/model.ckpt{suffix}', f'results/tabfact/model/model.ckpt-0{suffix}')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1519,"status":"ok","timestamp":1635160105509,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"SFCGaDIeugwj"},"outputs":[],"source":["max_seq_length = 512\n","tabfact_vocab_file = \"tabfact_model/vocab.txt\"\n","tabfact_config = tf_example_utils.ClassifierConversionConfig(\n","    vocab_file=tabfact_vocab_file,\n","    max_seq_length=max_seq_length,\n","    max_column_id=max_seq_length,\n","    max_row_id=max_seq_length,\n","    strip_column_names=False,\n","    add_aggregation_candidates=False,\n",")\n","tabfact_converter = tf_example_utils.ToClassifierTensorflowExample(tabfact_config)\n","\n","def tabfact_convert_interactions_to_examples(tables_and_queries):\n","  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n","  for idx, (table, queries) in enumerate(tables_and_queries):\n","    interaction = interaction_pb2.Interaction()\n","    for position, query in enumerate(queries):\n","      question = interaction.questions.add()\n","      question.original_text = query\n","      question.id = f\"{idx}-0_{position}\"\n","    for header in table[0]:\n","      interaction.table.columns.add().text = header\n","    for line in table[1:]:\n","      row = interaction.table.rows.add()\n","      for cell in line:\n","        row.cells.add().text = cell\n","    number_annotation_utils.add_numeric_values(interaction)\n","    for i in range(len(interaction.questions)):\n","      try:\n","        yield tabfact_converter.convert(interaction, i)\n","      except ValueError as e:\n","        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n","        \n","def tabfact_write_tf_example(filename, examples):\n","  with tf.io.TFRecordWriter(filename) as writer:\n","    for example in examples:\n","      writer.write(example.SerializeToString())\n","\n","def tabfact_predict_new(table_data, queries):\n","  table = table_data\n","  examples = tabfact_convert_interactions_to_examples([(table, queries)])\n","  tabfact_write_tf_example(\"results/tabfact/tf_examples/test.tfrecord\", examples)\n","  tabfact_write_tf_example(\"results/tabfact/tf_examples/dev.tfrecord\", [])\n","  \n","  ! python -m tapas.run_task_main \\\n","    --task=\"TABFACT\" \\\n","    --output_dir=\"results\" \\\n","    --noloop_predict \\\n","    --test_batch_size={len(queries)} \\\n","    --tapas_verbosity=\"ERROR\" \\\n","    --compression_type= \\\n","    --reset_position_index_per_cell \\\n","    --init_checkpoint=\"tabfact_model/model.ckpt\" \\\n","    --bert_config_file=\"tabfact_model/bert_config.json\" \\\n","    --mode=\"predict\" 2\u003e error\n","\n","\n","  results_path = \"results/tabfact/model/test.tsv\"\n","  all_results = []\n","  df = pd.DataFrame(table[1:], columns=table[0])\n","  # display(IPython.display.HTML(df.to_html(index=False)))\n","  print()\n","  with open(results_path) as csvfile:\n","    reader = csv.DictReader(csvfile, delimiter='\\t')\n","    for row in reader:\n","      supported = int(row[\"pred_cls\"])\n","      all_results.append(supported)\n","      score = float(row[\"logits_cls\"])\n","      position = int(row['position'])\n","      print(queries[position])\n","      if supported:\n","        print(\"\u003e YES\")\n","      else:\n","        print(\"\u003e NO\")\n","  print()\n","  return all_results"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":76093,"status":"ok","timestamp":1635160181591,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"DrrLOJcquj1T"},"outputs":[],"source":["os.makedirs('results/wtq/tf_examples', exist_ok=True)\n","os.makedirs('results/wtq/model', exist_ok=True)\n","with open('results/wtq/model/checkpoint', 'w') as f:\n","  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n","for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n","  shutil.copyfile(f'tapas_model/model.ckpt{suffix}', f'results/wtq/model/model.ckpt-0{suffix}')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1635160181593,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"pzofoUj4umUD"},"outputs":[],"source":["def isfloat(value):\n","  try:\n","    float(value)\n","    return True\n","  except ValueError:\n","    return False"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1635160181594,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"-wAkQW7zuou1"},"outputs":[],"source":["def Average(Values) :  \n","  res_avg = sum(float(x) for x in Values if x != 'nan') / len(Values)\n","  return str(res_avg)\n","  # res_average = np.mean(Values)\n","  # return str(res_average)\n","\n","def Count(Values) :\n","  return str(len(Values))\n","\n","def Sum(Values):\n","  if isfloat(Values[0]):\n","    return str(sum(float(x) for x in Values if x != 'nan'))\n","  else:\n","    return str(\"\")\n","  # return str(np.sum(Values))\n","\n","def Max(Values):\n","  pass\n","\n","def Min(Values):\n","  pass"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1635160181595,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"VL71XMlluqei"},"outputs":[],"source":["def predict_new(table_data, queries, display = False):\n","\n","  table = table_data\n","  examples = convert_interactions_to_examples([(table, queries)])\n","  write_tf_example(\"results/wtq/tf_examples/test.tfrecord\", examples)\n","  write_tf_example(\"results/wtq/tf_examples/random-split-1-dev.tfrecord\", [])\n","  \n","  ! python -m tapas.run_task_main \\\n","    --task=\"WTQ\" \\\n","    --output_dir=\"results\" \\\n","    --noloop_predict \\\n","    --test_batch_size={len(queries)} \\\n","    --tapas_verbosity=\"ERROR\" \\\n","    --compression_type= \\\n","    --reset_position_index_per_cell \\\n","    --init_checkpoint=\"tapas_model/model.ckpt\" \\\n","    --bert_config_file=\"tapas_model/bert_config.json\" \\\n","    --mode=\"predict\" 2\u003e error\n","\n","  ANSWERS = []\n","  results_path = \"results/wtq/model/test.tsv\"\n","  all_coordinates = []\n","  df = pd.DataFrame(table[1:], columns=table[0])\n","  print(\"\\n\\n\\n\")\n","  # display(IPython.display.HTML(df.to_html(index=False)))\n","  Method_mapper = {'AVERAGE' : Average , 'SUM' : Sum , 'COUNT' : Count , 'MAX' : Max , 'MIN' : Min}\n","  print()\n","  with open(results_path) as csvfile:\n","    reader = csv.DictReader(csvfile, delimiter='\\t')\n","    query_index = 0\n","\n","    for row in reader:\n","      coordinates = sorted(prediction_utils.parse_coordinates(row[\"answer_coordinates\"]))\n","      all_coordinates.append(coordinates)\n","      answers = ', '.join([table[row + 1][col] for row, col in coordinates])\n","      position = int(row['position'])\n","      aggregation = aggregation_to_string(int(row[\"pred_aggr\"]))\n","\n","      if display:\n","        print(\"\u003e\", queries[position])\n","      answer_text = str(answers)\n","      #print(aggregation ,  type(aggregation)  , answers , type(answers) , answer_text , type(answer_text) , sep = \"\\n\")\n","      # print(aggregation, answer_text)\n","\n","      if re.search(\"list\", queries[position]):\n","          answer_text += \"\\n\"\n","          ANSWERS.append(answer_text)\n","\n","      elif aggregation != \"NONE\":\n","        num_results = answer_text.split(\",\")\n","        num_results = [num.strip() for num in num_results]\n","\n","        num_results = [float(x) if x.isnumeric() else x for x in num_results]\n","        \n","        #print(\"NUMS : \" , num_results)\n","\n","        answer_text = f\"{aggregation} of {answer_text}\"\n","\n","        actual_answer = Method_mapper[aggregation](num_results)\n","\n","        answer_text = answer_text + \"\\n\" + actual_answer + \"\\n\"\n","        ANSWERS.append(actual_answer)\n","    \n","      else:\n","          answer_text += \"\\n\"\n","          ANSWERS.append(answer_text)\n","    \n","      if display:\n","        print(answer_text)\n","\n","        # print(\"EXPECTED = \", plotqa_data[queries[position]])\n","        # print(\"PREDICTED = \", answer_text)\n","\n","        print(\"\\n\")\n","\n","  return ANSWERS"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1635160181597,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"tuDv89N8uspj"},"outputs":[],"source":["max_seq_length = 512\n","vocab_file = \"tapas_model/vocab.txt\"\n","config = tf_example_utils.ClassifierConversionConfig(\n","    vocab_file=vocab_file,\n","    max_seq_length=max_seq_length,\n","    max_column_id=max_seq_length,\n","    max_row_id=max_seq_length,\n","    strip_column_names=False,\n","    add_aggregation_candidates=False,\n",")\n","converter = tf_example_utils.ToClassifierTensorflowExample(config)\n","\n","\n","def convert_interactions_to_examples(tables_and_queries):\n","  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n","  for idx, (table, queries) in enumerate(tables_and_queries):\n","    interaction = interaction_pb2.Interaction()\n","    for position, query in enumerate(queries):\n","      question = interaction.questions.add()\n","      question.original_text = query\n","      question.id = f\"{idx}-0_{position}\"\n","    for header in table[0]:\n","      interaction.table.columns.add().text = header\n","    for line in table[1:]:\n","      row = interaction.table.rows.add()\n","      for cell in line:\n","        row.cells.add().text = cell\n","    number_annotation_utils.add_numeric_values(interaction)\n","    for i in range(len(interaction.questions)):\n","      try:\n","        yield converter.convert(interaction, i)\n","      except ValueError as e:\n","        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n","        \n","def write_tf_example(filename, examples):\n","  with tf.io.TFRecordWriter(filename) as writer:\n","    for example in examples:\n","      writer.write(example.SerializeToString())\n","\n","def aggregation_to_string(index):\n","  if index == 0:\n","    return \"NONE\"\n","  if index == 1:\n","    return \"SUM\"\n","  if index == 2:\n","    return \"AVERAGE\"\n","  if index == 3:\n","    return \"COUNT\"\n","  raise ValueError(f\"Unknown index: {index}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1635160181600,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"kA5Zjga5uuTU"},"outputs":[],"source":["def get_csvfile_path(ind):\n","  return \"/content/plotqa/TEST/csv/FrRCNN_test_predicted_tables_0.5/\"+str(annot[ind][\"image_index\"])+\".csv\""]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1635160181602,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"YhlIwqvmuzBl"},"outputs":[],"source":["def get_list_of_list(path, display = False):\n","    df = pd.read_csv(path)\n","    df = df.astype(str)\n","    df.drop(axis = 1 , labels = ['Unknown' , 'xlabel' , 'ylabel' ,'title' , 'legend orientation'] , inplace= True , errors = 'ignore')\n","    df = df.sort_values(df.columns[0],ignore_index=True)\n","    if display:\n","        print(df)\n","\n","    list_of_list_1 = [[]]\n","    list_of_list_1[0] = list(df.columns)\n","    list_of_list_1.extend(df.values.tolist()) \n","    return list_of_list_1"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1635160181603,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"DvVaSyCcu0qE"},"outputs":[],"source":["def display_image_qa_pairs(img_id):\n","\n","  print(\"png/\"+str(img_id)+\".png\")\n","  for i, path in enumerate(images):\n","    if re.search(\"png/\"+str(img_id)+\".png\", path):\n","      break\n","\n","  # Image\n","  print(\"\\nImage:\\n\")\n","  print(images[i])\n","  img = mpimg.imread(images[i])\n","  imgplot = plt.imshow(img)\n","  plt.show()\n","\n","  questions = list()\n","  answers = list()\n","  print(\"\\nQA Pairs:\\n\")\n","  img_index = annot[i][\"image_index\"]\n","  count = 0\n","\n","  for j in qa[\"qa_pairs\"]:\n","    if j[\"image_index\"] == img_index:\n","      count  += 1\n"," \n","      print(f\"Q{count}: {j['question_string']}\")\n","      print(f\"Ans: {j['answer']}\")\n","      questions.append(j['question_string'])\n","      answers.append(j['answer'])\n","\n","  return i, questions, answers\n","\n","\n","# # global variable theirs\n","# def get_comparison(theirs, ours, questions, answers):\n","#   d = dict()\n","#   for ques, ans in theirs:\n","#     d[ques] = ans\n","\n","#   for ques, ans in ours:\n","#     d[ques] = ans\n","\n","#   for i in range(len(questions)):\n","#     print(questions[i])\n","#     print(\"EXPECTED: \" + str(answers[i]))\n","#     print(\"GOT: \" + str(d[questions[i]]))\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1635160181604,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"_hSgYFr8u3O_"},"outputs":[],"source":["def spilt_ratio(query):\n","    s1 = []\n","    s2 = []\n","    flag = False\n","    query = query.split()\n","    i = 0\n","    while i \u003c len(query):\n","        if query[i] != \"to\":\n","            s1.append(query[i])\n","            i = i + 1\n","        elif i+1 \u003c len(query):\n","            s2 = s1[:-1]\n","            s2.append(query[i+1])\n","            flag = True\n","            i = i + 2\n","        while flag and i \u003c len(query):\n","            s1.append(query[i])\n","            s2.append(query[i])\n","            i += 1\n","    return \" \".join(s1), \" \".join(s2)\n","\n","# works - \"What is the ratio of male workers in 1981 to 1980 for the country Hong Kong\"\n","# doesn't work - What is the ratio of the education completion rate of male students in Burkina Faso to that in Cabo Verde ?"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1635160181605,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"4TB-x-5Iu6uP"},"outputs":[],"source":["def find_ratio(q, list_of_list):\n","    q = re.sub(\"ratio\", \"\", q , flags = re.I)\n","    q1, q2 = spilt_ratio(q)\n","    res = predict_new(list_of_list, [q1, q2])\n","\n","    return str(float(res[0]) / float(res[1]))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1635160181610,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"n2rvfNofu-a-"},"outputs":[],"source":["def find_trend(q, list_of_list):\n","    def is_increasing(vals):\n","        return all(i \u003c= j for i, j in zip(vals, vals[1:]))\n","\n","    def is_decreasing(vals):\n","        return all(i \u003e= j for i, j in zip(vals, vals[1:]))\n","\n","\n","    query = \"get the list of all values\" + q[re.search(\"trend\", q, flags = re.I).end():]\n","    list_val = predict_new(list_of_list, [query]) \n","    vals = list(map(lambda val: float(val), list_val[0].split(\", \")))\n","\n","    if is_increasing(vals):\n","        return \"INCREASING\"\n","    elif is_decreasing(vals):\n","        return \"DECREASING\"\n","    else:\n","        return \"NONE\""]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1635160181613,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"8nbcSonivAB4"},"outputs":[],"source":["def find_median(q, list_of_list, columns):\n","    for col in columns:\n","        if re.search(col, q):\n","            query = \"get the list of all values in \" + col\n","            list_val = predict_new(list_of_list, [query])\n","            vals = list(map(lambda val: float(val), list_val[0].split(\", \")))\n","            return median(vals)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1635160181615,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"3_A4_H5GvBtZ"},"outputs":[],"source":["def find_difference(q, list_of_list, column):\n","    q = \"\".join(q.split(\"difference between\")[-1]).strip()\n","    pat = re.compile(r'\\band\\b')\n","    x = pat.search(q) \n","    if x != None:\n","      q1 = q[0: x.span()[0]]\n","      name2 = q[x.span()[1] :] \n","      qsplit = q1.split()\n","      q2 = qsplit[:-1]\n","      q2 = ' '.join(q2) + name2\n","      # print(q1)\n","      # print(q2)\n","      val1, val2 = predict_new(list_of_list, [q1, q2]) \n","        \n","      return str(abs(float(val1) - float(val2)))\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1635160181616,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"kQaScIS8vE4X"},"outputs":[],"source":["def find_range(q, list_of_list):\n","  subquery = q.split(\"range\")[-1].strip()\n","  q1 = \"maximum \" + subquery\n","  q2 = \"minimum \" + subquery\n","  maximum, minimum = predict_new(list_of_list, [q1, q2])\n","  return str(float(maximum) - float(minimum))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1635160181618,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"Cb0b8Te9vGvT"},"outputs":[],"source":["def find_quartiles(q, list_of_list, columns):\n","  for col in columns:\n","    if re.search(col, q):\n","      query = \"get the list of all values in \" + col\n","      list_val = predict_new(list_of_list, [query])\n","      vals = list(map(lambda val: float(val), list_val[0].split(\", \")))\n","      vals.sort()\n","      n = len(vals)\n","\n","      q1 = (n + 1)/4\n","      q3 = 3*(n + 1)/4\n","      # print(n, q1, q3)\n","      if (n + 1) % 4:\n","        q1_left = floor(q1)\n","        q1_right = ceil(q1)\n","        q1_value = ( vals[q1_left-1] + vals[q1_right-1] ) / 2\n","\n","      else:\n","        q1_value = vals[q1-1]\n","\n","\n","      if (3*(n + 1)) % 4:\n","        q3_left = floor(q3)\n","        q3_right = ceil(q3)\n","        q3_value = ( vals[q3_left-1] + vals[q3_right-1] ) / 2\n","      else:\n","        q3_value = vals[q3-1]\n","\n","      q2_value = median(vals)\n","\n","      return str(q1_value), str(q2_value), str(q3_value)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1635160181619,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"nAlRwc0mvIu7"},"outputs":[],"source":["def find_iqr(q1, q3):\n","  return str(float(q3) - float(q1))"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1635160181620,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"NM_EkMT459bA"},"outputs":[],"source":["RESULT_DICT = {'QUERIES' : [],'ANSWERS':[]}"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":535,"status":"ok","timestamp":1635161175940,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"30z_YHyrvKWx"},"outputs":[],"source":["def tapas_find_answers(question, columns, list_of_list, dic_labels):\n","\n","  \n","    unanswered = []\n","    for qes in question:\n","        qes = qes.lower()\n","        if re.search(\"x-axis\", qes):\n","            ans = dic_labels['xlabel']\n","            print(\"\u003e\", qes)\n","            print(\"X-axis label = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","           \n","\n","        elif re.search(\"y-axis\", qes):\n","            ans = dic_labels['ylabel']\n","            print(\"\u003e\", qes)\n","            print(\"Y-axis label = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","        \n","\n","        elif re.search(\"title\", qes):\n","            ans = dic_labels['title']\n","            print(\"\u003e\", qes)\n","            print(\"TITLE = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","          \n","        elif re.search(\"ratio\", qes):\n","            ans = find_ratio(qes, list_of_list)\n","            print(\"\u003e\", qes)\n","            print(\"RATIO = \", ans)\n","            print(\"\\n\")\n","\n","        elif re.search(\"median\", qes):\n","            ans = find_median(qes, list_of_list, columns)\n","            print(\"\u003e\", qes)\n","            print(\"MEDIAN = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","\n","        elif re.search(\"trend\", qes):\n","            ans = find_trend(qes, list_of_list)\n","            print(\"\u003e\", qes)\n","            print(\"TREND = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","\n","        elif re.search(\"difference\", qes):\n","            ans = find_difference(qes, list_of_list, columns)\n","            print(\"\u003e\", qes)\n","            print(\"DIFFERENCE = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","\n","        elif re.search(\"interquartile range\", qes):\n","            q1, _, q3 = find_quartiles(qes, list_of_list, columns)\n","            ans = find_iqr(q1, q3)\n","            print(\"\u003e\", qes)\n","            print(\"INTER-QUARTILE RANGE = \", ans)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","\n","        elif re.search(\"quartiles\", qes):\n","            q1, q2, q3 = find_quartiles(qes, list_of_list, columns)\n","            print(\"\u003e\", qes)\n","            print(\"FIRST QUARTILE (Q1) = \", q1)\n","            print(\"SECOND QUARTILE (Q2) = \", q2)\n","            print(\"THIRD QUARTILE (Q3) = \", q3)\n","            print(\"\\n\")\n","            RESULT_DICT['QUERIES'].append(qes)\n","            RESULT_DICT['ANSWERS'].append(ans)\n","\n","            \n","        elif re.search(\"range\", qes):\n","            ans = find_range(qes, list_of_list)\n","            print(\"\u003e\", qes)\n","            print(\"RANGE = \", ans)\n","            print(\"\\n\")\n","\n","        else:\n","            unanswered.append(qes)\n","            \n","    if unanswered:\n","        res = predict_new(list_of_list, unanswered, True) \n","        RESULT_DICT['QUERIES'].append(qes)\n","        RESULT_DICT['ANSWERS'].append(res)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":628,"status":"ok","timestamp":1635160182210,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"Lxg8p3STvMC3"},"outputs":[],"source":["def part_answer(parts, columns, list_of_list):\n","  to_return = []\n","  for part in parts:\n","    if re.search(\"ratio\", part, flags = re.I):\n","        ans = find_ratio(part, list_of_list)\n","        print(\"\u003e\", part)\n","        print(\"RATIO = \", ans)\n","        print(\"\\n\")\n","        to_return.append(ans)\n","\n","    elif re.search(\"median\", part, flags = re.I):\n","        ans = find_median(part, list_of_list, columns)\n","        print(\"\u003e\", part)\n","        print(\"MEDIAN = \", ans)\n","        print(\"\\n\")\n","        to_return.append(ans)\n","\n","    elif re.search(\"sum\", part, flags = re.I):\n","        ans = predict_new(list_of_list, [part])\n","        print(\"\u003e\", part)\n","        print(\"ANS FROM TAPAS = \", ans[0])\n","        print(\"\\n\")\n","        to_return.append(ans[0])\n","\n","    elif re.search(\"difference\", part, flags = re.I):\n","        ans = find_difference(part, list_of_list, columns)\n","        print(\"\u003e\", part)\n","        print(\"DIFFERENCE = \", ans)\n","        print(\"\\n\")\n","        to_return.append(ans)\n","\n","    elif re.search(\"trend\", part, flags = re.I):\n","        ans = find_trend(part, list_of_list)\n","        print(\"\u003e\", part)\n","        print(\"TREND = \", ans)\n","        print(\"\\n\")\n","        to_return.append(ans)\n","\n","    else:\n","        ans = predict_new(list_of_list, [part])\n","        print(\"\u003e\", part)\n","        print(\"ANS FROM TAPAS = \", ans[0])\n","        print(\"\\n\")\n","        to_return.append(ans[0])\n","        # return \"NOT_FOUND\"\n","  return to_return        \n","\n","def tabfact_find_answers(list_of_list, question, columns):\n","    unanswered = []\n","    pattern = re.compile(r'\\bgreat\\b|\\bgreater\\b|\\bhigh\\b|\\bhigher\\b|\\blow\\b|\\blower\\b|\\bless\\b|\\blesser\\b|\\bsmall\\b|\\bsmaller\\b|\\bequal\\b', flags=re.I | re.X)\n","    prelim = re.compile(r'\\bratio\\b|\\bmedian\\b|\\bdifference\\b|\\bsum\\b', flags=re.I | re.X)\n","    incdec = re.compile(r'\\bincrease\\b|\\bincreasing\\b|\\bdecrease\\b|\\bdecreasing\\b', flags=re.I | re.X)\n","    for qes in question:\n","        qes = qes.lower()\n","        if prelim.search(qes) != None:\n","          x = pattern.search(qes)\n","          if x != None:\n","            try:\n","              first_part = qes[0: x.span()[0]]\n","              second_part = qes[x.span()[1] : ] \n","\n","              # print(\"FIRST PART :\", first_part)\n","              # print(\"SECOND PART:\", second_part)\n","\n","              first_ans , second_ans = part_answer([first_part, second_part],  columns, list_of_list)\n","              # second_ans = part_answer(second_part, columns, list_of_list) \n","\n","              \n","              exact_match = x.group().lower()\n","              fl_fans = round(float(first_ans), 2)\n","              fl_sans = round(float(second_ans), 2)\n","\n","              if exact_match == \"equal\":\n","                if fl_fans == fl_sans:\n","                    print(\"\u003e SUPPORTS:\", qes)\n","                    RESULT_DICT['QUERIES'].append(qes)\n","                    RESULT_DICT['ANSWERS'].append(\"\u003eSUPPORTS\")\n","                else:\n","                  print(\"\u003e REFUTES\", qes)\n","                  RESULT_DICT['QUERIES'].append(qes)\n","                  RESULT_DICT['ANSWERS'].append(\"\u003eREFUTES\")\n","\n","              elif exact_match == \"great\" or exact_match == \"greater\" or exact_match == \"high\" or exact_match == \"higher\":\n","                if fl_fans \u003e fl_sans:\n","                  print(\"\u003e SUPPORTS:\", qes)\n","                  RESULT_DICT['QUERIES'].append(qes)\n","                  RESULT_DICT['ANSWERS'].append(\"\u003eSUPPORTS\")\n","                else:\n","                  print(\"\u003e REFUTES\", qes)\n","                  RESULT_DICT['QUERIES'].append(qes)\n","                  RESULT_DICT['ANSWERS'].append(\"\u003eREFUTES\")\n","\n","              else:\n","                if fl_fans \u003c fl_sans:\n","                  print(\"\u003e SUPPORTS:\", qes)\n","                  RESULT_DICT['QUERIES'].append(qes)\n","                  RESULT_DICT['ANSWERS'].append(\"\u003eSUPPORTS\")\n","                else:\n","                  print(\"\u003e REFUTES\", qes)\n","                  RESULT_DICT['QUERIES'].append(qes)\n","                  RESULT_DICT['ANSWERS'].append(\"\u003eREFUTES\")\n","\n","            except:\n","              unanswered.append(qes)\n","          else:\n","            unanswered.append(qes) \n","        else:\n","          unanswered.append(qes)\n","          # find_incdec  = incdec.search(qes)\n","          # if find_incdec != None:\n","          #   get_trend_for_qes = qes[0: find_incdec.span()[0]]\n","          #   final_qes = ' '.join(get_trend_for_qes.split()[:-1])\n","          #   final_qes = \"get trend for \" + final_qes\n","          #   got_ans = part_answer([final_qes],  columns, list_of_list)\n","          #   ans = got_ans[0]\n","\n","          #   exact_match = find_incdec.group().lower()\n","\n","          #   if exact_match in [\"increase\", \"increasing\"]:\n","          #     if ans == \"INCREASING\":\n","          #        print(\"\u003e SUPPORTS:\", qes)\n","          #     else:\n","          #        print(\"\u003e REFUTES\", qes)\n","          #   elif exact_match in [\"decrease\", \"decreasing\"]:\n","          #     if ans == \"DECREASING\":\n","          #       print(\"\u003e SUPPORTS:\", qes)\n","          #     else:\n","          #       print(\"\u003e REFUTES\", qes)\n","          #   else:\n","          #     print(\"\u003e REFUTES\", qes)\n","          \n","          # else:\n","          #   unanswered.append(qes)\n","\n","\n","    if unanswered:\n","        res = tabfact_predict_new(list_of_list, unanswered) "]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1635160182212,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"gWthqDGzvO66"},"outputs":[],"source":["from google.colab import files\n","import os\n","import glob\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import re\n","import json\n","from natsort import natsorted \n","import shutil\n","import pandas as pd\n","from statistics import median\n","from math import floor\n","from math import ceil\n","from distutils.dir_util import copy_tree\n","\n","import numpy as np\n","import pickle\n","%matplotlib inline"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1635160182214,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"8Frdwz_WvSlR"},"outputs":[],"source":["def final_answer(IMAGE_ID, questions):\n","\n","\n","  df = pd.read_csv('/content/final_csv/' + IMAGE_ID + '.csv')\n","  \n","\n","  dic_labels = dict()\n","  for col in df.columns:\n","    if col == 'xlabel':\n","      dic_labels['xlabel'] = df['xlabel'].iloc[-1].strip()\n","    elif col == 'ylabel':\n","      dic_labels['ylabel'] = df['ylabel'].iloc[-1].strip()\n","    elif col == 'title':\n","      dic_labels['title'] = df['title'].iloc[-1].strip()\n","  \n","\n","  df.drop(axis = 1 , labels = ['Unknown' , 'xlabel' , 'ylabel' ,'title' , 'legend orientation'] , inplace= True, errors = 'ignore')\n","  columns = list(df.columns)\n","\n","\n","  data = get_list_of_list('/content/final_csv/' + IMAGE_ID + '.csv', True)\n","\n","\n","  tapas_questions, tabfact_questions = binary_classifier_predict(questions)\n","  print(tapas_questions)\n","  print(tabfact_questions)\n","  tapas_find_answers(tapas_questions, columns, data, dic_labels)\n","  tabfact_find_answers(data, tabfact_questions, columns) "]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7923,"status":"ok","timestamp":1635160190126,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"UlquJFiSvVvA","outputId":"be2f2a69-a4c3-49ad-c366-bce3a8b33519"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n","Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask) (2.11.3)\n","Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask) (1.0.1)\n","Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask) (7.1.2)\n","Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask) (1.1.0)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eFlask) (2.0.1)\n","Collecting flask-ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask\u003e=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (7.1.2)\n","Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (1.1.0)\n","Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (1.0.1)\n","Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (2.11.3)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eFlask\u003e=0.8-\u003eflask-ngrok) (2.0.1)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eflask-ngrok) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eflask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eflask-ngrok) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eflask-ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"]}],"source":["!pip install Flask\n","!pip install flask-ngrok"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22270,"status":"ok","timestamp":1635160215934,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"VLbguU3j1Nmu","outputId":"fb4e96db-455d-412b-df57-1190eeb7b07e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1635160215937,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"BysIR_OV2DIz"},"outputs":[],"source":["!mkdir /content/final_csv"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":493,"status":"ok","timestamp":1635160557298,"user":{"displayName":"SOORYANATH.I.T PES1201802827PESU CSE STUDENT","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5CG_9uWIybMhs8TbuhSK-G3uIPeObkOn-KU4N=s64","userId":"09558958214862773585"},"user_tz":-330},"id":"MrY9NOUYKNiz"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"PDGAjmXX1EMm"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"," * Running on http://f34a-35-230-84-146.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n","['Acrosss How many years is the data collected ?', 'What is the x-axis if the plot ?']\n","   Year Cost of computers, communications and other services (% of commerical service exports\n","0  2009                                 11.572492831098636                                   \n","1  2010                                  9.930546961954043                                   \n","2  2011                                  10.63015825618017                                   \n","3  2012                                 11.047287194428689                                   \n","4  2013                                 12.254920332217369                                   \n","['Acrosss How many years is the data collected ?', 'What is the x-axis if the plot ?']\n","[]\n","\u003e what is the x-axis if the plot ?\n","X-axis label =  Year\n","\n","\n","is_built_with_cuda: True\n","is_gpu_available: False\n","GPUs: []\n","Training or predicting ...\n","Evaluation finished after training step 0.\n","\n","\n","\n","\n","\n","\u003e acrosss how many years is the data collected ?\n","COUNT of 2009, 2010, 2011, 2012, 2013\n","5\n","\n","\n","\n","['Acrosss How many years is the data collected ?', 'WHat is the x-axis of the plot ?']\n","   Year Cost of computers, communications and other services (% of commerical service exports\n","0  2009                                 11.572492831098636                                   \n","1  2010                                  9.930546961954043                                   \n","2  2011                                  10.63015825618017                                   \n","3  2012                                 11.047287194428689                                   \n","4  2013                                 12.254920332217369                                   \n","['Acrosss How many years is the data collected ?', 'WHat is the x-axis of the plot ?']\n","[]\n","\u003e what is the x-axis of the plot ?\n","X-axis label =  Year\n","\n","\n","is_built_with_cuda: True\n","is_gpu_available: False\n","GPUs: []\n","Training or predicting ...\n","Evaluation finished after training step 0.\n","\n","\n","\n","\n","\n","\u003e acrosss how many years is the data collected ?\n","COUNT of 2009, 2010, 2011, 2012, 2013\n","5\n","\n","\n","\n"]}],"source":["#DONOT RUN THIS CELL\n","\n","from flask import Flask , render_template , request , send_from_directory\n","import pandas as pd\n","from flask_ngrok import run_with_ngrok\n","import shutil\n","import glob\n","\n","app = Flask(__name__ , static_url_path = '/content/drive/MyDrive/Flask/static',static_folder = '', template_folder = '/content/drive/MyDrive/Flask/templates')\n","\n","run_with_ngrok(app)\n","\n","@app.route('/')\n","def hello_world():\n","   return render_template('Query_home.html')\n","\n","@app.route(\"/download\" , methods = ['GET','POST'])\n","def downloader():\n","  return send_from_directory('/content/STAGE-1/final_csv/', '333333.csv', as_attachment=True)\n","\n","@app.route(\"/QA_Results\" , methods= ['GET','POST'])\n","def Foo():\n","\n","  #RESULT_DICT = {'QUERIES' : [],'ANSWERS':[]}\n","\n","  input_file = request.files['DUMMY_IMAGE']\n","\n","  form_question_data = request.form\n","\n","  questions_from_form = []\n","\n","  for question_datum in form_question_data :\n","\n","    if question_datum.startswith('Query') : questions_from_form.append(request.form[question_datum])\n","\n","  print(questions_from_form)\n","\n","  file_store = '/content/final_csv/' + input_file.filename\n","\n","  input_file.save(file_store)  \n","  \n","  #sys.stdout = open('answers.txt','w')\n","  global RESULT_DICT\n","\n","  RESULT_DICT = {'QUERIES':[],'ANSWERS':[]}  \n","\n","  final_answer('333333', questions_from_form)\n","\n","  #sys.stdout = sys.__stdout__\n","\n","  '''d = pd.read_csv(r\"/content/STAGE-1/final_csv/333333.csv\")  \n","\n","  d.to_html(\"Table.htm\" , justify='center')\n","\n","  d_html = d.to_html()\n","\n","  d_html = d_html.replace('\u003ctable border=\"1\" class=\"dataframe\"\u003e' , '\u003ctable border=\"2px solid white\" style = \"color:white ; font-weight:900 ;\" class=\"dataframe\"\u003e')\n","\n","  d_html = d_html.replace('\u003ctr\u003e' , '\u003ctr border=\"2px solid white\"\u003e')\n","\n","  return render_template('Result.html' , data = d_html)'''\n","\n","  d = pd.DataFrame.from_dict(RESULT_DICT)\n","\n","  d.to_html(\"Tabler.htm\" , justify='center')\n","\n","  d_html = d.to_html()\n","\n","  d_html = d_html.replace('\u003ctable border=\"1\" class=\"dataframe\"\u003e' , '\u003ctable border=\"2px solid white\" style = \"color:white ; font-weight:900 ;\" class=\"dataframe\"\u003e')\n","\n","  d_html = d_html.replace('\u003ctr\u003e' , '\u003ctr border=\"2px solid white\"\u003e')\n","\n","  return render_template('Q_Result.html' , data = d_html)\n","\n","  \n","\n","\n","if __name__ == '__main__':\n","\n","   app.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5hM1XdUKzYi"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+2gNGYIx7B3gc/it+4/of","collapsed_sections":[],"name":"Web-App-2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}